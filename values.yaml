# Default values for er-frappe.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Number of PODs to be started
replicas:
  defaultworker: 1
  longworker: 1
  spinedispatcher: 1
  web: 1
  frappesocketio: 1
  #kafka: 0

targetNamespace: frappe11

# Target Environment - can be only beta-release or release
branch: release

# Control which components are to be enabled as part of this deployment.
# Ideally, all components should be deployed as part of single deployment
# However, in exceptional cases, where a specific component is not required,
# it can be disabled below by setting the corresponding value as false.
components:
  web: true
  scheduler: true
  longworker: true
  spinedispatcher: true
  defaultworker: true
  frappesocketio: true
  #kafka: false

hpa:
  web:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilization: 200 # As percentage
  longworker:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilization: 200 # As percentage
  defaultworker:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilization: 200 # As percentage
  spinedispatcher:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilization: 200 # As percentage
  frappesocketio:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilization: 200 # As percentage

# Allows for applications to define migration strategy deployed as initContainers
# The commands array is mandatory if this is enabled.
# Command will be executed using the same image, env and volumes as standard application
# Note that application will not be up and running when initContainers are executed.
# Scripts mentioned here must be able to execute successfully even when the application is not running
# The application containers will not be started until these scripts are completed successfully.
migration:
  enabled: false
  scripts:
    - "/home/frappe/docker-bench/migrate.sh"

persistence:
  # only azure, gke and local supported
  type: gke
  # only 'file' or 'disk' supported for azure. Ignored for local. gce-pd and nfs supported for GKE.
  subtype: nfs
  capacityInGi: 10
  # Storage account should already exist. Used only for type: azure
  #storageaccount: erbk8sappall
  # File share by this name must already exist in the storage account mentioned above.
  # This file share should also already have blank files named apps.txt and currentsite.txt.
  # Also copy common_site_config.json file with configuration details.
  # Used only for type: azure
  #sharename: frappe11-sites-share
  # base64 encoded storage account access key. Used only for type: azure
  #storageaccountkey: "V0FFOEdabWttZFRtWXE0cUF5TGd4azk1OGF4c1FzYUlSYlNQQWlJNk53L3IrbGZGbU40TG45ZERKZDhnQlZJalp3WWlCMFJOZ1dRN2lKUTFlN25JWnc9PQ=="
  #location: sea
  # Type & replication for persistent disk used in GKE - used only for type: gke, subtype: gce-pd
  pdType: pd-standard
  replicationType: none
  pdName: er-bk8s-trun-site-pd
  # NFS Server Details along with path which should be used to hold site data - used only for type: gke, subtype: nfs
  nfsServer: "10.68.0.2"
  # Base path where the files will be saved. Release name directory is expected to exist in this path.
  # The actual files should exist within the directory named with release name.
  nfsBasePath: /erbk8sappall/ntex-vol/non-prod-apps/er-bk8s-app-all/default

redisserver:
  enabled: true
  image:
    repository: redis
    tag: alpine
    pullPolicy: IfNotPresent
  bigcache:
    enabled: true
    clusterEnabled: false
    #Will be used only if cluster is enabled.
    replicaCount: 6
    service:
      type: ClusterIP
      port: 13100
    listenport: 6378
    maxmemory: 2048mb
    persistence:
      enabled: false
      storageCapacityinGi: 2
  cache:
    clusterEnabled: false
    #Will be used only if cluster is enabled.
    replicaCount: 6
    service:
      type: ClusterIP
      port: 13000
    listenport: 6379
    maxmemory: 292mb
    persistence:
      enabled: false
      storageCapacityinGi: 1
  queue:
    clusterEnabled: false
    #Will be used only if cluster is enabled.
    replicaCount: 6
    service:
      type: ClusterIP
      port: 11000
    listenport: 6381
    persistence:
      enabled: false
      storageCapacityinGi: 1
  socketio:
    clusterEnabled: false
    #Will be used only if cluster is enabled.
    replicaCount: 6
    service:
      type: ClusterIP
      port: 12000
    listenport: 6380
    persistence:
      enabled: false
      storageCapacityinGi: 1

# This configuration will not be used if redisserver.enabled is true.
redis:
  cache:
    targetHost: frappe11-cache-ntex-com
    targetPort: 13000
  socketio:
    targetHost: frappe11-socketio-ntex-com
    targetPort: 12000
  queue:
    targetHost: frappe11-queue-ntex-com
    targetPort: 11000

# Image details
image:
  #Image to be used for frappe/erpnext based application
  frappeapp:
    # Image name (including the registry, if using private registry)
    repository: dock.elasticrun.in/er-frappe11-base
    # Pull policy for the image above.
    pullPolicy: Always
    readinessProbe:
      httpGetPath: /app-health
    livenessProbe:
      httpGetPath: /app-health
  # Image to be used for monitoring sidecar for frappe container.
  redis:
    repository: redis
    tag: alpine
    pullPolicy: IfNotPresent
  monitoring:
    #
    enabled: false
    repository:
    tag:
    pullPolicy:
    port:
    protocol:
  fluentd:
    enabled: true
    repository: dock.elasticrun.in/er-fluentd-base
    pullPolicy: Always
    externalPort: 24224
    elasticHost: elasticsearch.ntex.com
    elasticPort: 9200
    indexname: er-bk8s-app-all
    gelfEnabled: true

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  port: 80
  ## externalTrafficPolicy denotes if this Service desires to route external
  ## traffic to node-local or cluster-wide endpoints. "Local" preserves the
  ## client source IP and avoids a second hop for LoadBalancer and Nodeport
  ## type services, but risks potentially imbalanced traffic spreading.
  ## "Cluster" obscures the client source IP and may cause a second hop to
  ## another node, but should have good overall load-spreading.
  externalTrafficPolicy: Cluster
  # Only applies to Service Type: "LoadBalancer". LoadBalancer will get
  # created with the IP specified in this field. This feature depends on
  # whether the underlying cloud-provider supports specifying the loadBalancerIP
  # when a load balancer is created. This field will be ignored if the
  # cloud-provider does not support the feature.
  loadBalancerIP: ""

db:
  hostIP: 10.75.0.97
  port: 3306
  # Should be base64 encoded value of the actual password
  # encoded Value for 'Ntex@123'
  rootPassword: TnRleEAxMjM=

web:
  gunicorn:
    connections_per_worker: 25
    workers: 2

## Optional /etc/hosts contents
etchosts:
  - ip: 10.60.0.4
    hostnames:
      - beta-release-spine.ntex.com
  - ip: 10.210.2.21
    hostnames:
      - release-spine.ntex.com
  - ip: 10.160.0.23
    hostnames:
      - beta-release-db.ntex.com
      - release-db.ntex.com
  - ip: 10.70.0.8
    hostnames:
      - beta-release-elasticsearch.ntex.com
      - release-elasticsearch.ntex.com

  # - ip: 1
  #   hostnames:
  #     - release-db.ntex.com

# Used only when kafka component is enabled.
kafka:
  zookeeper:
    persistence:
      enabled: true
      subtype: nfs
      capacityInGi: 8
      pdName: "zk-pd"
      annotations: {}
      accessModes:
        - "ReadWriteOnce"
  persistence:
      enabled: true
      subtype: nfs
      pdName: "kafka-pd"
      capacityInGi: 100
      annotations: {}
      accessModes:
        - "ReadWriteOnce"
  externalAccess:
    enabled: false
    externalIPs: []
  # base64 encoded passwords for broker authentication and interbroker authentication.
  brokerauth: bnRleEAxMjM=
  interbrokerauth: bnRleEAxMjM=
  heapOpts: "-Xmx1024m -Xms1024m"
  options: ""

site:
  # Must be base64 encoded value for administrator password for the newly created site.
  # encoded value for Nt3x!@#
  adminPassword: TnQzeCFAIw==
  dbname: frappe11db

ingress:
  enabled: true
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # service.beta.kubernetes.io/azure-load-balancer-internal: "true"
  hosts:
    - host: elasticrun.in
      paths: ["/"]
  tls: #[]
    - secretName: erun-ssl-cert
      hosts:
        - elasticrun.in

# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
resources: #{}
  web: #{}
    limits:
      cpu: 750m
      memory: 1024Mi
    requests:
      cpu: 150m
      memory: 128Mi
  defaultworker: #{}
    limits:
      cpu: 750m
      memory: 1024Mi
    requests:
      cpu: 150m
      memory: 128Mi
  longworker: #{}
    limits:
      cpu: 250m
      memory: 512Mi
    requests:
      cpu: 50m
      memory: 128Mi
  scheduler: #{}
    limits:
      cpu: 300m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  spinedispatcher: #{}
    limits:
      cpu: 500m
      memory: 1024Mi
    requests:
      cpu: 100m
      memory: 128Mi
  frappesocketio: #{}
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 25m
      memory: 32Mi
  logcollector: #{}
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 25m
      memory: 32Mi
  monitor: #{}
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 25m
      memory: 32Mi
  cache: #{}
    # memory limits for cache should be enough to accomodate
    # maxmemory configuration in redisserver above.
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 25m
      memory: 32Mi
  bigcache:
    # memory limits for cache should be enough to accomodate
    # maxmemory configuration in redisserver above.
    limits:
      cpu: 250m
      memory: 2Gi
    requests:
      cpu: 50m
      memory: 256Mi
  queue: #{}
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 25m
      memory: 32Mi
  socketio: #{}
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 25m
      memory: 32Mi
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}
